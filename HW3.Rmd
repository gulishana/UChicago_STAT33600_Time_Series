---
title: "STAT33600 Homework 3"
author: "Sarah Adilijiang"
output:
  pdf_document: default
  html_notebook: default
---

## Section 3.1 Autoregressive Moving Average Models

## 3.1

For model MA(1): $x_t = w_t + \theta w_{t-1}$, the autocovariance function is:
$$\gamma_x(h) = Cov(x_{t+h},x_t) = Cov(w_{t+h} + \theta w_{t+h-1}, w_t + \theta w_{t-1})$$
$$
= (\theta^2+1)\gamma_w(h) + \theta \ [\gamma_w(h+1)+\gamma_w(h-1)]
= \left\{ \begin{array}{ll} 
(\theta^2+1)\sigma_w^2 & if \ h=0  \\
\theta\sigma_w^2  & if \ |h|=1 \\
0 & if \ |h| \geq 2
\end{array} \right. 
$$

So the ACF function is:
$$
\rho_x(h) = \frac{\gamma_x(h)}{\gamma_x(0)} = \left\{ \begin{array}{ll} 
1 & if \ h=0  \\
\frac{\theta}{\theta^2+1}  & if \ |h|=1 \\
0 & if \ |h| \geq 2
\end{array} \right.
$$

Because $\theta^2+1 \geq |2\theta| \ \ \ \forall \theta$, and the equation holds when $|\theta|=1$ 

$$\Rightarrow |\rho_x(1)| = \left| \frac{\theta}{\theta^2+1} \right| = \frac{|\theta|}{\theta^2+1} \leq \frac{|\theta|}{|2\theta|} = \frac{1}{2}  \ \ \ \ \ \ \forall \theta$$

And $\max \rho_x(1) = 1/2$, when $\theta=1$; $\min \rho_x(1) = -1/2$, when $\theta=-1$






## 3.2

### (a)

Since $x_t = \phi x_{t-1} + w_t$, and $x_0 = w_0$, so:

$$x_t = \phi x_{t-1} + w_t = \phi (\phi x_{t-2} + w_{t-1}) + w_t = \phi^2x_{t-2} +\phi w_{t-1} + w_t = \cdots = \sum_{j=0}^t \phi^j w_{t-j} \ \ \ \ \ (t=0,1,2,...)$$



### (b)

$$E(x_t) = E\left( \sum_{j=0}^t \phi^j w_{t-j} \right) = \sum_{j=0}^t \phi^j E(w_{t-j}) = 0 \ \ \ \ \ (t=0,1,2,...)$$



### (c)

$$Var(x_t) = Var(\sum_{j=0}^t \phi^j w_{t-j}) = \sum_{i=0}^t \sum_{j=0}^t Cov(\phi^i w_{t-i}, \phi^j w_{t-j}) = \sum_{j=0}^t Var(\phi^j w_{t-j})$$

$$= \sum_{j=0}^t \phi^{2j} \sigma_w^2 \ = \frac{\sigma_w^2}{1-\phi^2} (1-\phi^{2(t+1)}) \ \ \ \ \ (t=0,1,2,...)$$



### (d)

For $h\geq0$, we have:

$$Cov(x_{t+h},x_t) = Cov \left(\sum_{i=0}^{t+h} \phi^i w_{t+h-i}, \sum_{j=0}^t \phi^j w_{t-j} \right) = \sum_{i=0}^{t+h} \sum_{j=0}^t Cov(\phi^i w_{t+h-i}, \phi^j w_{t-j})$$

$$= \sum_{j=0}^t Cov(\phi^{j+h} w_{t-j}, \phi^j w_{t-j}) = \sum_{j=0}^t \phi^{2j+h} \sigma_w^2 \ = \phi^h Var(x_t)$$



### (e)
The mean function is constant 0, but the autocovariance function is:
$$\gamma_x(h) = Cov(x_{t+h},x_t) = \phi^h Var(x_t) = \frac{\phi^h \sigma_w^2}{1-\phi^2} (1-\phi^{2(t+1)})$$
which depends on time $t$.

Therefore, series $x_t$ is not stationary.




### (f)

Since $|\phi| < 1$, so we have:

$$\gamma_x(h) = \frac{\phi^h \sigma_w^2}{1-\phi^2} (1-\phi^{2(t+1)}) \ \longrightarrow \ \frac{\phi^h \sigma_w^2}{1-\phi^2} \ \ (\text{ as } t \rightarrow \infty) $$

So when $t \rightarrow \infty$, the autocovariance function is converged to a constant which does not depend on time $t$ but only on the lag $h$.

Therefore, the series $x_t$ is asymptotically stationary.




### (g)

From (f) we get that as $t \rightarrow \infty$, the AR(1) model is asymptotically stationary. Therefore, it will converge to a stationary process while the time t is large enough. 

Based on this conclusion, we can first simulate number m (m is much larger than n) samples of iid N(0,1) values, assign a constant $|\phi|<1$, then compute the accumulated sum of the samples using the formula: $x_t = \sum_{j=0}^t \phi^j w_{t-j}$. This will generate number m observations of the AR(1) model. In the end, we only take the last number n of the m observations, so this last number n samples will be a stationary series.




### (h)

Suppose $x_0 = w_0/\sqrt{1-\phi^2}$, then we have:

$$x_t = \sum_{j=0}^{t-1} \phi^j w_{t-j} + \phi^t x_0 = \sum_{j=0}^{t-1} \phi^j w_{t-j} + \frac{\phi^t w_0}{\sqrt{1-\phi^2}}   \ \ \ \ \ (t=1,2,...)$$

(1) Mean function

When $t=0$, the mean function is $E(x_t) = E(x_0) = 0$; when $t\geq0$, the mean function is:

$$E(x_t) = E\left( \sum_{j=0}^{t-1} \phi^j w_{t-j} + \frac{\phi^t w_0}{\sqrt{1-\phi^2}} \right) = \sum_{j=0}^{t-1} \phi^j E(w_{t-j}) + \frac{\phi^t E(w_0)}{\sqrt{1-\phi^2}} = 0 \ \ \ \ \ (t=1,2,...)$$

(2) Autocovariance function:

$$Var(x_t) = Var \left( \sum_{j=0}^{t-1} \phi^j w_{t-j} + \frac{\phi^t w_0}{\sqrt{1-\phi^2}} \right) = \sum_{j=0}^{t-1} Var(\phi^j w_{t-j}) + \frac{\phi^{2t} \sigma_w^2}{1-\phi^2}$$

$$= \sum_{j=0}^{t-1} \phi^{2j} \sigma_w^2 + \frac{\phi^{2t} \sigma_w^2}{1-\phi^2} = \frac{\sigma_w^2}{1-\phi^2} (1-\phi^{2t}) + \frac{\phi^{2t} \sigma_w^2}{1-\phi^2} = \ \frac{\sigma_w^2}{1-\phi^2} \ \ \ \ \ (t=0,1,2,...)$$
which is a constant.

Thus, for $h\geq0$, the autocovariance function is:

$$\gamma_x(h)= Cov(x_{t+h},x_t) = Cov \left( \sum_{i=0}^{t+h-1} \phi^i w_{t+h-i} + \frac{\phi^{t+h} w_0}{\sqrt{1-\phi^2}}, \ \sum_{j=0}^{t-1} \phi^j w_{t-j} + \frac{\phi^t w_0}{\sqrt{1-\phi^2}} \right)$$

$$= \sum_{i=0}^{t+h-1} \sum_{j=0}^{t-1} Cov(\phi^i w_{t+h-i}, \phi^j w_{t-j}) + \frac{\phi^{2t+h} \sigma_w^2}{1-\phi^2} \ = \ \sum_{j=0}^{t-1} Cov(\phi^{j+h} w_{t-j}, \phi^j w_{t-j}) + \frac{\phi^{2t+h} \sigma_w^2}{1-\phi^2}$$

$$= \sum_{j=0}^{t-1} \phi^{2j+h} \sigma_w^2 + \frac{\phi^{2t+h} \sigma_w^2}{1-\phi^2} \ = \ \phi^h Var(x_t) \ = \ \frac{\phi^h \sigma_w^2}{1-\phi^2}$$
which only depends on lag $h$ but not depends on time $t$.


As a result, based on (1) and (2), the series $x_t$ is stationary.






## 3.4 ARMA(p,q) models

### (a)

$$x_t = 0.80x_{t-1} - 0.15x_{t-2} + w_t - 0.30w_{t-1}$$
$$x_t - 0.80x_{t-1} + 0.15x_{t-2} = w_t - 0.30w_{t-1}$$
$$(1 - 0.80B + 0.15B^2) \ x_t = (1 - 0.30B) \ w_t$$

So:
$$\phi(B) = 1 - 0.80B + 0.15B^2 = (1-0.30B)(1-0.50B)$$
and:
$$\theta(B) = 1 - 0.30B$$

Hence the common factor $1 - 0.30B$ can be canceled and get that:
$$(1-0.50B) \ x_t = \ w_t$$
$$x_t = 0.50x_{t-1} + w_t$$
which is a AR(1) model.

This AR(1) model is causal because the root of $\phi(z) = 1- 0.50z = 0$ is $z=2$ , which is outside the unit circle.

This AR(1) model is also intertible, because it can be written as $w_t = x_t - 0.50x_{t-1} = (1-0.50B) \ x_t$.




### (b)

$$x_t = x_{t-1} - 0.50x_{t-2} + w_t - w_{t-1}$$
$$x_t - x_{t-1} + 0.50x_{t-2} = w_t - w_{t-1}$$
$$(1 - B + 0.50B^2) \ x_t = (1 - B) \ w_t$$

So:
$$\phi(B) = 1 - B + 0.50B^2$$
and:
$$\theta(B) = 1 - B$$

There is no common factor, so this is a ARMA(2,1) model.

This ARMA(2,1) model is causal because the root of $\phi(z) = 1- z + 0.50z^2 = 0$ are complex roots: $z=1\pm \sqrt{-1} = 1 \pm i$. Since $|1 \pm i|^2 = 2$,  which are both outside the unit circle.

This ARMA(2,1) model is not intertible, because the root of $\theta(z) = 1 - z$ is $z=1$, which is not outside the unit circle.







## 3.5

For the AR(2) model:

$$x_t = \phi_1 x_{t-1} + \phi_2 x_{t-2} + w_t$$
$$x_t - \phi_1 x_{t-1} - \phi_2 x_{t-2} = w_t$$
$$(1 - \phi_1 B - \phi_2 B^2) \ x_t = w_t$$

So:
$$\phi(B) = 1 - \phi_1 B - \phi_2 B^2$$

And autoregressive polynomial is:
$$\phi(z) =  1 - \phi_1 z - \phi_2 z^2$$

And the roots of it are:
$$z_1, z_2 = \frac{\phi_1 \pm \sqrt{\phi_1^2 + 4\phi_2}}{-2\phi_2}$$
where $z_1,z_2$ can be real and distinct, real and equal, or a complex conjugate pair.

And we can get that:
$$\phi(z) =  1 - \phi_1 z - \phi_2 z^2 = (1-\frac{z}{z_1})(1-\frac{z}{z_2}) = 1 - (\frac{1}{z_1} + \frac{1}{z_2})z + \frac{1}{z_1z_2}z^2$$

$$\Rightarrow \ \ \ \ \ \ \ \ \ \phi_1 = \frac{1}{z_1} + \frac{1}{z_2}, \ \ \ \ \ \ \ \ \phi_2 = -\frac{1}{z_1z_2}  $$

Therefore, this AR(2) process is causal when the roots $z_1,z_2$ both lie outside the unit circle, i.e. $|z_1| >1, |z_2|>1$.

Now we prove that the causal conditions $|z_1|>1$ and $|z_2|>1$ are equivalent to the following three conditions: 
$$\phi_1 + \phi_2 - 1 = \ \frac{1}{z_1} + \frac{1}{z_2} -\frac{1}{z_1z_2} - 1 = \ -(1-\frac{1}{z_1})(1-\frac{1}{z_2}) \ < 0 \ \ \ \ \ \ \ \ \text{(1)}$$
$$\phi_2 - \phi_1 - 1 = \ -\frac{1}{z_1z_2} - \frac{1}{z_1} -\frac{1}{z_2} -1 = \ -(1+\frac{1}{z_1})(1+\frac{1}{z_2}) \ < 0 \ \ \ \ \ \ \ \ \text{(2)}$$ 
$$|\phi_2| = \left| \frac{1}{z_1z_2} \right| < 1 \ \ \iff  \ |z_1z_2| > 1 \ \ \ \ \ \ \ \ \text{(3)}$$

Note that in these three inequations, the positions of $z_1,z_2$ are symmetric.


(1) Sufficiency

When $\phi_1+\phi_2<1, \ \phi_2-\phi_2<1, \ |\phi_2|<1$ holds:

If $z_1,z_2$ are real, then $|z_1z_2| = |z_1| |z_2|>1$ shows that at least one of $z_1,z_2$ is larger than 1. Since their positions in the three equations are symmetric, we can suppose that $|z_1|>1$. Let's multiply (1) by (2) and get that: $(1-\frac{1}{z_1^2})(1-\frac{1}{z_2^2}) > 0$, since $|z_1|>1$, so $(1-\frac{1}{z_1^2})>0$, thus $(1-\frac{1}{z_2^2})>0$, i.e. we also have $|z_2|>1$.

If $z_1,z_2$ are a complex conjugate pair $a\pm bi$, then we have $|z_1z_2| = a^2+b^2>1$, so we can get that both $|z_1| = |z_2| = |a\pm bi| = \sqrt{a^2+b^2} > 1$, i.e. $|z_1|>1, |z_2|>1$.

Therefore, in both cases, we can get that $|z_1|>1, |z_2|>1$.



(2) Necessity

When $|z_1|>1, |z_2|>1$ holds:

If $z_1,z_2$ are real, then we have $|z_1z_2|>1$, so (3) holds. And $(1\pm\frac{1}{z_1})>0$, $(1\pm\frac{1}{z_1})>0$, so that both (1) and (2) hold.

If $z_1,z_2$ are a complex conjugate pair $a\pm bi$, then $|z_1| = |z_2| = |a\pm bi| = \sqrt{a^2+b^2} > 1$, thus we have $|z_1z_2| = a^2+b^2 >1$, so (3) holds. Further, since the reciprocals of a complex conjuate pair $\frac{1}{z_1},\frac{1}{z_2} = \frac{a\mp bi}{a^2+b^2}$ are also a complex conjugate pair, and that $|\frac{1}{z_1}| = |\frac{1}{z_2}| = \frac{\sqrt{a^2+b^2}}{a^2+b^2} = \frac{1}{\sqrt{a^2+b^2}} < 1$. As a result, for (1), $(1-\frac{1}{z_1})(1-\frac{1}{z_2}) = |1-\frac{1}{z_1}|^2 > 0$, so (1) holds. And for (2), $(1+\frac{1}{z_1})(1+\frac{1}{z_2}) = |1+\frac{1}{z_1}|^2 > 0$, so (2) holds.

Therefore, in both cases, we can get that $\phi_1+\phi_2<1, \ \phi_2-\phi_2<1, \ |\phi_2|<1$.

Conclusion:

Based on the above sufficiency and necessity, we have proved that:
$$\text{AR(2) is causal}  \ \ \iff \ \ |z_1|>1, |z_2|>1 \ \ \iff \ \ \phi_1+\phi_2<1, \ \phi_2-\phi_2<1, \ |\phi_2|<1$$






## Section 3.2 Difference Equations

## 3.6

$$x_t = - 0.9x_{t-2} + w_t$$
$$x_t + 0.9x_{t-2} = w_t$$
$$(1 + 0.9B^2) \ x_t = w_t$$

So the autoregressive polynomial is:
$$\phi(z) =  1 + 0.9z^2$$

And the roots of it are:
$$z = \pm \ \frac{i}{\sqrt{0.9}}$$

The plot of the ACF $\rho(h)$ is shown as below:
```{r}
ACF = ARMAacf(ar=c(0,-0.9), ma=0, lag.max=50)
plot((0:50), ACF, type="h", xlab="lag h")
abline(h=0)
```




















